{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cherishings/Deep_Learning/blob/main/Lab_3_Part_3_PyTorch_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3, Part 3 Image Recognition in PyTorch"
      ],
      "metadata": {
        "id": "tNb_cWGohNaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Introduction\n",
        "\n",
        "**Note: before starting save a copy of this file in your own Google Drive - go to File and click Save a copy in Drive**\n",
        "\n",
        "The objective of this part of the lab is to understand how to design and implement a deep convolutional network in Python with PyTorch, for image recognition, i.e. classification of an image.\n",
        "\n",
        "In this lab the dataset is the well-known Fashion MNIST data set, where there are 10 classes of different types of clothing.\n",
        "\n",
        "This part of the lab essentially replicates the image recognition problem in Keras from part 2 of the lab, demonstrating how to design and evaluate a CNN in PyTorch."
      ],
      "metadata": {
        "id": "TPMvIZCfhO3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Methods\n",
        "\n",
        "#### **Data**\n",
        "\n",
        "In this lab the problem is one of multiclass classification and therefore the input data $\\mathbf{x}$ is an image (that we will write as a vector for convenience - just assume the image is flattened into a vector for notational convenience), and the class label output data $y$ is one of 10 class values, representing different types of clothing.\n",
        "\n",
        "#### **Model**\n",
        "\n",
        "The model predicts the probabilty of each class based on a deep convolutional  network,\n",
        "$$ \\hat{\\mathbf{y}} = f\\left( \\phi(\\mathbf{x}) ; \\boldsymbol{\\theta} \\right) $$\n",
        "where $\\hat{\\mathbf{y}}$ is the prediction of the probability of each model class arising from a softmax output layer function $f$; For notational convenience we represent all model parameters in a vector $\\boldsymbol{\\theta}$, which comprises all the model parameters in the deep network. The function $\\phi(\\mathbf{x})$ performs feature extraction on the input  and is constructed from layers of simple functions, mainly convolutional functions here.\n",
        "\n",
        "The model uses chains of convolutional layers, among other types of layer, to extract features from the raw input image, to obtain $\\phi(\\mathbf{x})$, where the convolutional layer is described as\n",
        "\\begin{equation}\n",
        "    z_{i,j,k}^{(l)} = \\sum_{c}^{}{\\sum_{m}^{}{\\sum_{n}^{}{w_{m,n,c,k}^{(l)}x_{i + m,j + n,c}^{(l - 1)} + b_{k}^{(l)}}}} \\quad \\text{for} \\quad k = 1,\\ldots,N_{F}\n",
        "\\end{equation}\n",
        "where $N_{F}$ is the number of filters. The output of the convolutional layer is passed through a nonlinear activation function\n",
        "\\begin{equation}\n",
        "    x_{i,j,k}^{(l)} = h\\left( z_{i,j,k}^{(l)} \\right)\n",
        "\\end{equation}\n",
        "where the activation function $h(.)$ could be e.g. a rectified linear\n",
        "unit (ReLU).\n",
        "\n",
        "#### **Loss function**\n",
        "\n",
        "The loss function, $J(\\boldsymbol{\\theta})$, that we minimise to estimate the model parameters, $\\boldsymbol{\\theta}$, is the categorical cross-entropy loss for multiclass classification,\n",
        "$$ J(\\boldsymbol{\\theta}) =  - \\sum_{j = 1}^{m}{{\\sum_{k = 1}^{K} y_{j,k}\\log{\\hat{y}}_{j,k}}} $$\n",
        "where the number of classes $K=10$ and $m$ is the number of data samples. \\\\\n",
        "\n",
        "\n",
        "#### **Parameter estimation algorithm**\n",
        "\n",
        "The parameter estimation algorithm here is based on the Adam algorithm, which combines a momemtum-like term, $v_{j}$, with an adaptive learning rate, $r_{j}$, and bias corrected versions of these terms, $\\hat{v}_j $ and $ \\hat{r}_j$, where the $j$-th parameter update is\n",
        "\n",
        "\\begin{equation}\n",
        "    \\theta_{j} \\leftarrow \\theta_{j} - \\frac{\\epsilon}{\\sqrt{\\hat{r}_{j}}} \\hat{v}_{j}\n",
        "\\end{equation}\n",
        "\n",
        "where $\\epsilon$ is a learning rate and\n",
        "\n",
        "\\begin{gather}\n",
        "    \\hat{r}_j = \\frac{r_{j}}{1- \\beta_1^t} \\\\\n",
        "    \\hat{v}_j = \\frac{v_{j}}{1- \\beta_2^t} \\\\\n",
        "    v_{j} \\leftarrow \\beta_1 v_{j} + \\left( 1 - \\beta_1 \\right)g_{j} \\\\\n",
        "    r_{j} \\leftarrow \\beta_2 r_{j} + \\left( 1 - \\beta_2 \\right)g_{j}^{2}  \n",
        "\\end{gather}\n",
        "where $t$ is the time-step of the optimization and $g_j$ is the stochastic estimate of the loss function gradient for parameter $j$,\n",
        "\\begin{equation}\n",
        "        g_{j} = \\nabla_{\\boldsymbol{\\theta}} \\hat{J}(\\theta_j)\n",
        "\\end{equation}\n",
        "and  the estimate of the gradient of the loss function $\\nabla_{\\boldsymbol{\\theta}} \\hat{J}(\\boldsymbol{\\theta})$ is obtained from a mini-batch of data via automatic differentiation.\n"
      ],
      "metadata": {
        "id": "lW2nhCC5hU1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Import packages"
      ],
      "metadata": {
        "id": "xp7lxBPY_Atk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing essential libraries and modules for deep learning and visualization\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "f1SHz3uzcDO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Data preprocessing\n",
        "\n",
        "Note that in PyTorch the batch size for training is set here at the Data Loader stage.\n",
        "\n"
      ],
      "metadata": {
        "id": "GoW6X8xY--jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary transformations module from torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define a transformation pipeline.\n",
        "# Here, we're only converting the images to PyTorch tensor format.\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Using torchvision, load the Fashion MNIST training dataset.\n",
        "# root specifies the directory where the dataset will be stored.\n",
        "# train=True indicates that we want the training dataset.\n",
        "# download=True will download the dataset if it's not present in the specified root directory.\n",
        "# transform applies the defined transformations to the images.\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Create a data loader for the training set.\n",
        "# It will provide batches of data, in this case, batches of size 64.\n",
        "# shuffle=True ensures that the data is shuffled at the start of each epoch.\n",
        "# num_workers=2 indicates that two subprocesses will be used for data loading.\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "# Similarly, load the Fashion MNIST test dataset.\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the class labels for the Fashion MNIST dataset.\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
      ],
      "metadata": {
        "id": "_o6Ezm5ZcN_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Define the CNN model\n",
        "\n",
        "In PyTorch, we define the the neural network in a class with a constructor that defines the layers, and a method (or function) that defines the forward pass through the network - here the network is named ConvNet.\n",
        "\n",
        "A feature of PyTorch compared to Keras and Matlab is that you need to calculate the size of an input to a layer. This can be simple for convolutional layers (if you parameterise the number of filters and keep it constant) where the number of features map inputs is equivalent to the number of filters at the preceding layer .\n",
        "\n",
        "However, for the final linear (fully connected) layer this can be more complicated - in this case the input image is 28x28 but the maxpool downsamples them to 14x14. So the final linear layer needs to take account of this.\n",
        "\n",
        "The correct size of the final linear layer input at nn.Linear is: num_filters * 14 * 14.\n",
        "Let's see how that number is acheived.\n",
        "* The input image is 28x28.\n",
        "* The first convolution has padding of 1, and kernel size of 3, so the output feature map is also 28x28.\n",
        "* The MaxPool2d layer halves the spatial dimensions (28 / 2 = 14).\n",
        "* The second convolution layer, again with padding of 1 and a kernal size of 3, does not alter the 14x14 dimension.\n",
        "* The flatten layer then turns the num_filters x 14 x 14 tensor into a 1 dimensional tensor of length num_filters * 14 * 14.\n",
        "\n",
        "Note that to avoid having to\n",
        "\n",
        "You can check out the PyTorch docs for info on exactly how each layer works:\n",
        "https://pytorch.org/docs/stable/nn.html"
      ],
      "metadata": {
        "id": "4CJzDG7__Qvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ConvNet model\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_filters=4, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, num_filters, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_filters)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(num_filters * 14 * 14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = ConvNet(num_filters=16, num_classes=10)\n",
        "\n",
        "# print the model to inspect\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "YKPMiwGIfADW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6 Train the model\n",
        "\n",
        "The model is trained here using the categorical cross-entropy loss with Adam optimizer.\n",
        "\n",
        "Note that in PyTorch, unlike Keras, you have to explicitly code out the main steps in the training algorithm for each epoch of training and iterate over these steps in a for loop.\n",
        "\n",
        "In addition, you have to explicitly evaluate performance on validation data in a separate for loop."
      ],
      "metadata": {
        "id": "9AgfACNj-6KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "        optimizer.zero_grad()              # initialise loss function gradients\n",
        "        outputs = model(images)            # forward pass through network\n",
        "        loss = criterion(outputs, labels)  # compute the loss\n",
        "        loss.backward()                    # backward pass for loss function gradients\n",
        "        optimizer.step()                   # update model parameters\n",
        "\n",
        "        running_loss += loss.item()        # accumulate the loss\n",
        "        _, predicted = torch.max(outputs.data, 1)  # get the predicted class\n",
        "        total += labels.size(0)                    # number of predictions\n",
        "        correct += (predicted == labels).sum().item()  # sum correct predictions\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader)  # epoch loss\n",
        "    epoch_accuracy = 100 * correct / total        # epoch accuracy\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_accuracy:.2f}%')\n",
        "\n",
        "    # Validation loop - to monitor accuracy on independent validation data\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_loss / len(testloader)\n",
        "    val_epoch_accuracy = 100 * val_correct / val_total\n",
        "    print(f'Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "Yg5BWMk9-6uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.7 Evaluate the model"
      ],
      "metadata": {
        "id": "bMzMNKRa_Yqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the model to evaluation mode. This is important as certain layers like dropout behave differently during training and evaluation.\n",
        "model.eval()\n",
        "\n",
        "# Lists to store all predictions and true labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# We don't want to compute gradients during evaluation, hence wrap the code inside torch.no_grad()\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Iterate over all batches in the test loader\n",
        "    for images, labels in testloader:\n",
        "        # No device transfer needed as we are running on CPU\n",
        "\n",
        "        # Pass the images through the model to get predictions\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Get the class with the maximum probability as the predicted class\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Extend the all_preds list with predictions from this batch\n",
        "        all_preds.extend(predicted.numpy()) # removed .cpu()\n",
        "\n",
        "        # Extend the all_labels list with true labels from this batch\n",
        "        all_labels.extend(labels.numpy()) # removed .cpu()\n",
        "\n",
        "# Print a classification report which provides an overview of the model's performance for each class\n",
        "print(classification_report(all_labels, all_preds, target_names=classes))\n",
        "\n",
        "# Compute the confusion matrix using true labels and predictions\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn's heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues, xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted Label')  # x-axis label\n",
        "plt.ylabel('True Label')       # y-axis label\n",
        "plt.title('Confusion Matrix')  # Title of the plot\n",
        "plt.show()                     # Display the plot"
      ],
      "metadata": {
        "id": "ZDpJmS2_gLpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End of part 3 of the lab"
      ],
      "metadata": {
        "id": "_PZuZvPv9MKN"
      }
    }
  ]
}