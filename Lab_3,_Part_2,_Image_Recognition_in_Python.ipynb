{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cherishings/Deep_Learning/blob/main/Lab_3%2C_Part_2%2C_Image_Recognition_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3, Part 2 Image Recognition in Python with Keras-Tensorflow"
      ],
      "metadata": {
        "id": "CXnBAgz6f4uY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Introduction\n",
        "\n",
        "**Note: before starting save a copy of this file in your own Google Drive - go to File and click Save a copy in Drive**\n",
        "\n",
        "The objective of this part of the lab is to understand how to design and implement a deep convolutional network in Python with Keras-Tensorflow, for image recognition, i.e. classification of an image.\n",
        "\n",
        "In this lab the dataset is the well-known Fashion MNIST data set, where there are 10 classes of different types of clothing."
      ],
      "metadata": {
        "id": "EWgeRBVIf_Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Methods\n",
        "\n",
        "#### **Data**\n",
        "\n",
        "In this lab the problem is one of multiclass classification and therefore the input data $\\mathbf{x}$ is an image (that we will write as a vector for convenience - just assume the image is flattened into a vector for notational convenience), and the class label output data $y$ is one of 10 class values, representing different types of clothing.\n",
        "\n",
        "#### **Model**\n",
        "\n",
        "The model predicts the probabilty of each class based on a deep convolutional  network,\n",
        "$$ \\hat{\\mathbf{y}} = f\\left( \\phi(\\mathbf{x}) ; \\boldsymbol{\\theta} \\right) $$\n",
        "where $\\hat{\\mathbf{y}}$ is the prediction of the probability of each model class arising from a softmax output layer function $f$; For notational convenience we represent all model parameters in a vector $\\boldsymbol{\\theta}$, which comprises all the model parameters in the deep network. The function $\\phi(\\mathbf{x})$ performs feature extraction on the input  and is constructed from layers of simple functions, mainly convolutional functions here.\n",
        "\n",
        "The model uses chains of convolutional layers, among other types of layer, to extract features from the raw input image, to obtain $\\phi(\\mathbf{x})$, where the convolutional layer is described as\n",
        "\\begin{equation}\n",
        "    z_{i,j,k}^{(l)} = \\sum_{c}^{}{\\sum_{m}^{}{\\sum_{n}^{}{w_{m,n,c,k}^{(l)}x_{i + m,j + n,c}^{(l - 1)} + b_{k}^{(l)}}}} \\quad \\text{for} \\quad k = 1,\\ldots,N_{F}\n",
        "\\end{equation}\n",
        "where $N_{F}$ is the number of filters. The output of the convolutional layer is passed through a nonlinear activation function\n",
        "\\begin{equation}\n",
        "    x_{i,j,k}^{(l)} = h\\left( z_{i,j,k}^{(l)} \\right)\n",
        "\\end{equation}\n",
        "where the activation function $h(.)$ could be e.g. a rectified linear\n",
        "unit (ReLU).\n",
        "\n",
        "#### **Loss function**\n",
        "\n",
        "The loss function, $J(\\boldsymbol{\\theta})$, that we minimise to estimate the model parameters, $\\boldsymbol{\\theta}$, is the categorical cross-entropy for multiclass classification,\n",
        "$$ J(\\boldsymbol{\\theta}) =  - \\sum_{j = 1}^{m}{{\\sum_{k = 1}^{K} y_{j,k}\\log{\\hat{y}}_{j,k}}} $$\n",
        "where the number of classes $K=10$ and $m$ is the number of data samples. \\\\\n",
        "\n",
        "\n",
        "#### **Parameter estimation algorithm**\n",
        "\n",
        "The parameter estimation algorithm here is based on the Adam algorithm, which combines a momemtum-like term, $v_{j}$, with an adaptive learning rate, $r_{j}$, and bias corrected versions of these terms, $\\hat{v}_j $ and $ \\hat{r}_j$, where the $j$-th parameter update is\n",
        "\n",
        "\\begin{equation}\n",
        "    \\theta_{j} \\leftarrow \\theta_{j} - \\frac{\\epsilon}{\\sqrt{\\hat{r}_{j}}} \\hat{v}_{j}\n",
        "\\end{equation}\n",
        "\n",
        "where $\\epsilon$ is a learning rate and\n",
        "\n",
        "\\begin{gather}\n",
        "    \\hat{r}_j = \\frac{r_{j}}{1- \\beta_1^t} \\\\\n",
        "    \\hat{v}_j = \\frac{v_{j}}{1- \\beta_2^t} \\\\\n",
        "    v_{j} \\leftarrow \\beta_1 v_{j} + \\left( 1 - \\beta_1 \\right)g_{j} \\\\\n",
        "    r_{j} \\leftarrow \\beta_2 r_{j} + \\left( 1 - \\beta_2 \\right)g_{j}^{2}  \n",
        "\\end{gather}\n",
        "where $t$ is the time-step of the optimization and $g_j$ is the stochastic estimate of the loss function gradient for parameter $j$,\n",
        "\\begin{equation}\n",
        "        g_{j} = \\nabla_{\\boldsymbol{\\theta}} \\hat{J}(\\theta_j)\n",
        "\\end{equation}\n",
        "and  the estimate of the gradient of the loss function $\\nabla_{\\boldsymbol{\\theta}} \\hat{J}(\\boldsymbol{\\theta})$ is obtained from a mini-batch of data via automatic differentiation.\n",
        "\n"
      ],
      "metadata": {
        "id": "ccFKDEu9j2n-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsUj6cmDAz6O"
      },
      "source": [
        "## 2.3 Import data\n",
        "\n",
        "This section imports the standard data set Fashion MNIST from an online repository. It should take just a few seconds to download and unzip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEtCRLE47aC8"
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Input, Conv2D, MaxPooling2D, Flatten, Softmax\n",
        "from keras import optimizers, regularizers\n",
        "\n",
        "# import data\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# print data info\n",
        "print('Number of training data:' , len(train_images))\n",
        "print('Number of testing data:' , len(test_images))\n",
        "\n",
        "# define class labels\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "num_classes = 10 # number of classes\n",
        "\n",
        "# display example image\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BBouh5hBM7d"
      },
      "source": [
        "## 2.4 Data pre-processing\n",
        "\n",
        "This section performs some basic data pre-processing with data normalisation and splitting into training and testing data sets.\n",
        "\n",
        "This section also displays some example class images from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0_cyP2RBOeO"
      },
      "source": [
        "# normalise image data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# display some sample images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()\n",
        "\n",
        "# These are gray-scale images and therefore they only have a depth of 1, unlike\n",
        "# a colour image that would have a depth of 3 (RGB values). However, the depth\n",
        "# is not explcitly stored so we need to explicitly set the image\n",
        "# depth to 1 so that it is the shape Keras is expecting\n",
        "train_img = np.expand_dims(train_images, axis=-1)\n",
        "test_img = np.expand_dims(test_images, axis=-1)\n",
        "print(train_img[19].shape)\n",
        "print(test_img[11].shape)\n",
        "\n",
        "# define the training and test labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_to6NqolAcmu"
      },
      "source": [
        "## 2.5 Model design\n",
        "\n",
        "Note that the network design has two convolutional blocks:\n",
        "\n",
        "Conv --> Batch norm --> ReLU\n",
        "\n",
        "and a max pooling layer is used for dimension reduction\n",
        "\n",
        "In the quiz, you will be prompted to change the number of filters, but it is set low to start with at num_filters = 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sdze7rt74xx"
      },
      "source": [
        "# number of convolutional filters\n",
        "num_filters = 4\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Input(shape=(28,28,1)))  # image input size is 28x28x1\n",
        "\n",
        "model.add(Conv2D(num_filters, kernel_size =(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size =(2, 2), strides=(2, 2), padding= 'same'))\n",
        "\n",
        "model.add(Conv2D(num_filters, kernel_size =(3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Softmax())\n",
        "\n",
        "# set the optimization options and compile the model\n",
        "opt = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# print out the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8ORgYnTB5YP"
      },
      "source": [
        "## 2.6 Train the model\n",
        "\n",
        "This section trains the deep convolutional network using the Adam algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To9AhhUkVt9w"
      },
      "source": [
        "history = model.fit(train_img, train_labels, batch_size=64, epochs=10, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Plot accuracy and loss over training iterations\n",
        "\n",
        "Plot accuracy and loss over training epochs (for both training data and validation data) - it is important to monitor convergence of the algorithm via these plots to assess whether the parameter estimation has converged."
      ],
      "metadata": {
        "id": "4fY2FDdnugPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IccIOgP9uyRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Print out the accuracy on the independent Test data set\n"
      ],
      "metadata": {
        "id": "TCGYEn_5YoL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the accuracy on independent test data\n",
        "score = model.evaluate(test_img, test_labels, verbose=0)\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "TdTS_B8lYn47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.9 Confusion matrix\n",
        "\n",
        "Calculate and display the confusion matrix for this problem - the confusion matrix is important to inspect because it gives more insight into classifier performance across all classes than simply inspecting accuracy, which obscures detail."
      ],
      "metadata": {
        "id": "DPXl1Cb1woev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain model predictions and convert softmax outputs 0-1 to integer class label predictions\n",
        "Yhat = model.predict(test_img)                    # predict model outputs on validation data as softmax outputs of probability of each class\n",
        "Yhat_integer = np.argmax(Yhat, axis=1)            # obtain the most likely class prediction as the argument of the max softmax output\n",
        "Y_test_integer = np.argmax(test_labels, axis=1)   # obtain the true class as an integer\n",
        "\n",
        "# calculate and plot confusion matrix\n",
        "cm = confusion_matrix(Y_test_integer, Yhat_integer , normalize=\"pred\")    # calculate the confusion matrix\n",
        "plt.figure(2).set_figwidth(15)                                            # setup new figure\n",
        "sns.heatmap(cm/np.sum(cm), annot=True, fmt=\".2%\", cmap=\"Blues\",)          # plot the confusion matrix using the sns package\n",
        "plt.title(\"Confusion Matrix\", fontsize = 12)                              # title\n",
        "plt.xlabel(\"Predicted Class\", fontsize = 12)                              # xlabel\n",
        "plt.ylabel(\"True Class\", fontsize = 12)                                   # ylabel\n",
        "plt.show()                                                                # show plot"
      ],
      "metadata": {
        "id": "qfUPeV8Swr5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that for the confusion matrix, all the 10 classes are equally split, so the max accuracy per class is 10% - for 10 classes this adds up to 100% (the point being that 10% accuracy for any single class is the best possible result)."
      ],
      "metadata": {
        "id": "DBoegfzoQtpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End of part 2 of the lab"
      ],
      "metadata": {
        "id": "chs8VDdx4xAp"
      }
    }
  ]
}